{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNIST Handwriting Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to explore the potential of machine learning by building a handwriting recogniser using TensorFlow.\n",
    "\n",
    "**Every ML Problem....** concerns the building of models that when given a never-seen-before input, returns useful information about the input as output. \n",
    "\n",
    "```\n",
    "   Input --> Model --> Output\n",
    "```\n",
    "\n",
    "A **model** is said to map *input* to *output* and can be described by a mathematical equation. \n",
    "\n",
    "For example, this could be a model\n",
    "\n",
    "```\n",
    "   y = mx\n",
    "```\n",
    "\n",
    "where:\n",
    "- *y* is the output\n",
    "- *x* is the input\n",
    "- *m* is something unknown\n",
    "\n",
    "*m* is often known as a **parameter** or a **weight**.\n",
    "\n",
    "This model is **untrained** because we dont know beforehand what the value of *m* should be. \n",
    "To **train** a model means to choose an optimal value for *m*.\n",
    "\n",
    "There are many techniques to train models. Techniques are usually either **supervised learning** or **unsupervised learning**.\n",
    "\n",
    "Unsupervised learning involves feeding a model example input/output pairs to learn parameters\n",
    "\n",
    "```\n",
    "   Training Inputs ---> Model\n",
    "   Training Labels ------^\n",
    "```\n",
    "\n",
    "**In this exercise...** we'll build and train a model that when given an image containing a handwritten number, returns the number displayed in the image\n",
    "\n",
    "```\n",
    "   Image of a handwritten number --> Model --> The number displayed in the image\n",
    "```\n",
    "\n",
    "We are going to use unsupervised learning to train our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ML models out there, including models made up of models. When choosing what model to use, a common starting question is.\n",
    "\n",
    "> What do we want the output of our model to look like?\n",
    "\n",
    "In our case, we'd like our model to give an output that reads\n",
    "\n",
    "> I'm 90% sure its an 8, but there is a 10% chance its a 9\n",
    "\n",
    "With that in mind, we'll use the **softmax regression model**. The output of this model will be a vector of 10 numbers between 0 and 1 that sum up to 1. The nth number will be the probability of the image containing the nth digit (according to the model). E.g.\n",
    "\n",
    "```\n",
    "   0, 0, 0, 0, 0, 0, 0, 0.9, 0, 0.1\n",
    "```\n",
    "\n",
    "When our trained softmax regression model is asked to detect the number in a never-seen-before image, it will do so in two steps\n",
    "\n",
    "- Calculate the **evidence** in the image that would indicate the presence of each number\n",
    "- Convert the 10 pieces of evidence into **probabilities**\n",
    "\n",
    "##### Calculating evidence\n",
    "The evidence for the presence of the number $one$ in an image would be defined as\n",
    "\n",
    "$\\text{evidence}_{one} = \\sum_{j}^{pixels} W_{one,~ j} x_j + b_{one}$\n",
    "\n",
    "- $x_j$ represents the intensity value of pixel $j$ in the image.\n",
    "- $W_{one, ~ j}$ represents a weight for the pixel $j$ in an image containing the number $one$\n",
    "- $b$ represents the **bias** for the number $one$. \n",
    "\n",
    "Note that *weights* and *bias* values are parameters which need to be learnt\n",
    "\n",
    "##### Turning evidence into probability\n",
    "\n",
    "$\\text{evidence}_{one}$, $\\text{evidence}_{two}$, ..., $\\text{evidence}_{nine}$ are then combined to make a probability vector (the model's output).\n",
    "\n",
    "This is achieved using the **softmax function** which acts as a normalizer of the 10 generated evidence values, making sure they add up to 1. The evidence values are exponentialised to ensure that if there is relatively high evidence for particular digit, its given much more favor in the final output.\n",
    "\n",
    "Our finished model can be visualised as such:\n",
    "\n",
    "![title](https://www.tensorflow.org/versions/r0.9/images/softmax-regression-scalargraph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does the model look like in Code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # Input\n",
    "W = tf.Variable(tf.zeros([784, 10]))        # Parameter (to be learned in training) \n",
    "b = tf.Variable(tf.zeros([10]))             # Parameter (to be learned in training)\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)      # Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "The shape of mnist_training_data_images is  (55000, 784)\n",
      "The shape of mnist_training_data_labels is (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# load the training data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "mnist_training_data = mnist.train\n",
    "mnist_training_data_images = mnist_training_data.images\n",
    "mnist_training_data_labels = mnist_training_data.labels\n",
    "print \"The shape of mnist_training_data_images is \", mnist_training_data.images.shape\n",
    "print \"The shape of mnist_training_data_labels is\", mnist_training_data.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining a single piece of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def view_image(images, n):\n",
    "    image = images[n]\n",
    "    image.resize(28,28)\n",
    "    plt.imshow(image, cmap='Greys')\n",
    "    \n",
    "def view_image_labels(labels, n):\n",
    "    print \"Label for image\",n ,\"is\", labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# playground!\n",
    "\n",
    "# what is the smallest pixel value in the first image?\n",
    "# what is the largest pixel value in the first image?\n",
    "# what does the first image in mnist_training_data look like?\n",
    "#view_image(mnist_training_data.images, 4)\n",
    "# what does the label for the first image in mnist_training_data look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model is an interative process.\n",
    "\n",
    "On each iteration we\n",
    "- **Score** the model\n",
    "- Update the values for the model parameters (**training step**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To score a model during training we define a **loss function** which we can use to ask\n",
    "\n",
    "- Is it sufficiently trained? \n",
    "- Should we stop training here?\n",
    "- Should we carry on training? \n",
    "- Is it worse than the last iteration?\n",
    "- Is it better than the last iteration?\n",
    "\n",
    "The goal during training is to build a model with the smallest loss as possible.\n",
    "\n",
    "Our loss function involves feeding our in-training model a batch of images and comparing the model's verdict against the truth. If the models verdict is significantly different from the truth, the loss is high. If they are similar the loss is low.\n",
    "\n",
    "The one we will use in our example is called **cross-entropy**.\n",
    "\n",
    "$cross\\_entropy = H_{y'}(y) = -\\sum_i y'_i \\log(y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What does the lost function look like in code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "loss_function = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update step uses the output of **lost function** to work out which parameters can be tweaked (and by how much) in order to make the cost lower in the next iteration.\n",
    "\n",
    "This training step is done via **backwards propagation**.\n",
    "\n",
    "The most common type of backwards propagation is called **gradient descent**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What does the training step look like in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-912ade90b7c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100) # take a random 100 images and labels from the training set\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9175\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying it out on your own image! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try drawing a number [here](http://drawisland.com/?w=28&h=28), then place it in the data folder of this project and use the methods below to run it through your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "import Image\n",
    "\n",
    "def prepare_image(image_file):\n",
    "    image = Image.open(image_file)\n",
    "    grey_image = image.convert('L') # convert RGBA to greyscale\n",
    "    flat_array = np.resize(np.array(grey_image.getdata()), (1,784))\n",
    "    flat_array = flat_array.astype(np.float32)\n",
    "    flat_array /= 255.0\n",
    "    return 1 - flat_array\n",
    "    \n",
    "def detect_number(sess, image_file):\n",
    "    image = prepare_image(image_file)\n",
    "    prediction = tf.argmax(y,1)\n",
    "    print sess.run(prediction, feed_dict={x: image})\n",
    "    return\n",
    "\n",
    "detect_number(sess, '/data/2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good? In your spare time, try improving your handwriting recogniser by using a neural network for a model\n",
    "https://www.tensorflow.org/versions/r0.9/tutorials/mnist/pros/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
